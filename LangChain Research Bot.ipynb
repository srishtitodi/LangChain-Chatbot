{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c596f809",
   "metadata": {},
   "source": [
    "### Importing libraries and defining API key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f929e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.chains import RetrievalQA,  ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "import os\n",
    "import openai\n",
    "import sys\n",
    "os.environ['OPENAI_API_KEY'] = dummy_key     #mention your API key\n",
    "sys.path.append('../..')\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de22b3b7",
   "metadata": {},
   "source": [
    "### Loading the PDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e2ab6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the chatbot on 4 research pdfs \n",
    "\n",
    "loaders = [\n",
    "    # Duplicate documents on purpose - messy data\n",
    "    PyPDFLoader(\"Downloads/political bias.pdf\"),\n",
    "    PyPDFLoader(\"Downloads/evidence based trustworthiness by dan roth.pdf\"),\n",
    "    PyPDFLoader(\"Downloads/yi zhang data provenance.pdf\"),\n",
    "    PyPDFLoader(\"Downloads/trustworthy social bias measurement.pdf\")\n",
    "]\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d53424c",
   "metadata": {},
   "source": [
    "### Splitting the text into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b9d105",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369b3a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = text_splitter.split_documents(docs)\n",
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79d7174",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff18499",
   "metadata": {},
   "source": [
    "### Storing the data in a vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa929899",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "embedding = OpenAIEmbeddings()                      #embedding the textual input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a9c3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = 'docs/chroma/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711e2b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectordb = Chroma.from_documents(\n",
    "#     documents=splits,\n",
    "#     embedding=embedding,\n",
    "#     persist_directory=persist_directory\n",
    "# )\n",
    "vectordb = Chroma(\n",
    "    persist_directory=persist_directory,\n",
    "    embedding_function=embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab788ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681a2400",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"explain the bias measurement framework.\"\n",
    "# question = \"what did you learn about bias?\"\n",
    "# question = \"what are the biases known to you?.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9612bf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(question,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5197b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5aa3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_mmr=vectordb.max_marginal_relevance_search(question,k=3, fetch_k=2)  # retrieving the documents based on mmr search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8242be91",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_mmr[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28ddea7",
   "metadata": {},
   "source": [
    "#### Though here the output is same, there are certain cases where mmr would give better results than a similarity search "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbb5847",
   "metadata": {},
   "source": [
    "### Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4a8007",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5585f0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"source\",\n",
    "        description=\"The research paper the chunk is, should be one of 'Downloads/political bias.pdf','Downloads/evidence based trustworthiness by dan roth.pdf','Downloads/yi zhang data provenance.pdf', `Downloads/trustworthy social bias measurement.pdf`\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"page\",\n",
    "        description=\"The page from the research paper\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a6a9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_content_description = \"Research notes\"\n",
    "llm = OpenAI(model='gpt-3.5-turbo', temperature=0)                 #defining the model to be used and the randomness in response\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vectordb,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1345d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about embedding bias in the fourth pdf?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bb6e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.get_relevant_documents(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3d15bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006fb117",
   "metadata": {},
   "source": [
    "### Retrieval QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163d4da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "llm = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65f98a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what are some bias measurements?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928c63b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007c5f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9febac",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d91312",
   "metadata": {},
   "source": [
    "### Defining a prompt for the bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800b7afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Build prompt\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b9a9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e9b80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what is divdist framework for bias measurement? Explain in detail.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4e7440",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2679662d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb48786",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"source_documents\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee980e8d",
   "metadata": {},
   "source": [
    "### Experimenting retrieval with different chain types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fcf678",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain_mr = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    chain_type=\"map_reduce\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4aeb19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa_chain_mr({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bcc892",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1479fda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain_mr = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    chain_type=\"refine\"\n",
    ")\n",
    "result = qa_chain_mr({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619155ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Summarize the fourth pdf in detail.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23bf55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain_mr = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    chain_type=\"refine\"\n",
    ")\n",
    "result = qa_chain_mr({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca60efc",
   "metadata": {},
   "source": [
    "### Retrieval QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e73360a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build prompt\n",
    "from langchain.prompts import PromptTemplate\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate(input_variables=[\"context\", \"question\"],template=template,)\n",
    "\n",
    "# Run chain\n",
    "from langchain.chains import RetrievalQA\n",
    "question = \"Summarize the research paper 'trustworthy socia bias measurement ' in detail.\"\n",
    "qa_chain = RetrievalQA.from_chain_type(llm,\n",
    "                                       retriever=vectordb.as_retriever(),\n",
    "                                       return_source_documents=True,\n",
    "                                       chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT})\n",
    "\n",
    "\n",
    "result = qa_chain({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ef892f",
   "metadata": {},
   "source": [
    "### Saving the previous chats using Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef7ddde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e7f380",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "retriever=vectordb.as_retriever()\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fefd20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Summarize the research paper 'trustworthy social bias measurement ' in detail.\"\n",
    "result = qa({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9acd6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a596faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"does divdist framework overcome the shortcomings in previous measures?\"\n",
    "result = qa({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d2426e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab299f24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
